{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries importeren en random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x143f0984810>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data inladen en naar dataframe omzetten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>[Hi, Hi there, Hola, Hello, Hello there, Hya, ...</td>\n",
       "      <td>[Hi human, please tell me your GeniSys user, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>[My user is Adam, This is Adam, I am Adam, It ...</td>\n",
       "      <td>[Great! Hi &lt;HUMAN&gt;! How can I help?, Good! Hi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CourtesyGreeting</td>\n",
       "      <td>[How are you?, Hi how are you?, Hello how are ...</td>\n",
       "      <td>[Hello, I am great, how are you? Please tell m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CourtesyGreetingResponse</td>\n",
       "      <td>[Good thanks! My user is Adam, Good thanks! Th...</td>\n",
       "      <td>[Great! Hi &lt;HUMAN&gt;! How can I help?, Good! Hi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CurrentHumanQuery</td>\n",
       "      <td>[What is my name?, What do you call me?, Who d...</td>\n",
       "      <td>[You are &lt;HUMAN&gt;! How can I help?, Your name i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     intent  \\\n",
       "0                  Greeting   \n",
       "1          GreetingResponse   \n",
       "2          CourtesyGreeting   \n",
       "3  CourtesyGreetingResponse   \n",
       "4         CurrentHumanQuery   \n",
       "\n",
       "                                                text  \\\n",
       "0  [Hi, Hi there, Hola, Hello, Hello there, Hya, ...   \n",
       "1  [My user is Adam, This is Adam, I am Adam, It ...   \n",
       "2  [How are you?, Hi how are you?, Hello how are ...   \n",
       "3  [Good thanks! My user is Adam, Good thanks! Th...   \n",
       "4  [What is my name?, What do you call me?, Who d...   \n",
       "\n",
       "                                           responses  \n",
       "0  [Hi human, please tell me your GeniSys user, H...  \n",
       "1  [Great! Hi <HUMAN>! How can I help?, Good! Hi ...  \n",
       "2  [Hello, I am great, how are you? Please tell m...  \n",
       "3  [Great! Hi <HUMAN>! How can I help?, Good! Hi ...  \n",
       "4  [You are <HUMAN>! How can I help?, Your name i...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open('Data/Intent.json'))\n",
    "df = pd.DataFrame(data['intents'])\n",
    "df = df[['intent', 'text', 'responses']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functies maken voor tokenizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\boris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence.lower())\n",
    "\n",
    "def stem (word):\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "    sentence_words = [stem(w) for w in tokenized_sentence]\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Woordenlijst maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    tag = intent[\"intent\"]\n",
    "    tags.append(tag)\n",
    "    \n",
    "    for pattern in intent[\"text\"]:\n",
    "        w = tokenize(pattern)\n",
    "        all_words.extend(w)\n",
    "        xy.append((w, tag))\n",
    "        \n",
    "all_words = sorted(set(stem(w) for w in all_words if w not in [\"?\", \".\", \"!\"]))\n",
    "tags = sorted(set(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traindata samenstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for pattern_sentence, tag in xy:\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    Y_train.append(tags.index(tag))\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = Y_train\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.x_data[index], dtype=torch.float32), torch.tensor(self.y_data[index], dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=8, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intent Classifier netwerk bouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(len(X_train[0]), 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, len(tags))\n",
    ")\n",
    "print(len(X_train[0]))\n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss & optimalisator declareren en check voor cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "criterium = nn.CrossEntropyLoss()\n",
    "optimalisator = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "component = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                         else \"cpu\")\n",
    "model = model.to(component)\n",
    "print(component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100 / 500], Loss: 0.0090\n",
      "Epoch [200 / 500], Loss: 0.0017\n",
      "Epoch [300 / 500], Loss: 0.0006\n",
      "Epoch [400 / 500], Loss: 0.0001\n",
      "Epoch [500 / 500], Loss: 0.0001\n",
      "Training voltooid! Gewichten opslaan...\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for words, labels in train_loader:\n",
    "                \n",
    "        words = words.to(component)\n",
    "        labels = labels.to(component)\n",
    "        \n",
    "        outputs = model(words)\n",
    "        loss = criterium(outputs, labels)\n",
    "        \n",
    "        optimalisator.zero_grad()\n",
    "        loss.backward()\n",
    "        optimalisator.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch + 1} / {num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "print(\"Training voltooid! Gewichten opslaan...\")\n",
    "torch.save(model.state_dict(), \"Getrainde_modellen/NLP_Model_gewichten.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratie na training: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct_voorspeld = 0\n",
    "    totaal_voorspeld = 0\n",
    "    \n",
    "    for words, labels in train_loader:\n",
    "        words, labels = words.to(component), labels.to(component)\n",
    "        test_output = model(words)\n",
    "        _, predicted = torch.max(test_output, 1)\n",
    "        correct_voorspeld += (predicted == labels).sum().item()\n",
    "        totaal_voorspeld += labels.size(0)\n",
    "\n",
    "accuratie = correct_voorspeld / totaal_voorspeld * 100\n",
    "\n",
    "print(f\"Accuratie na training: {accuratie:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat implementatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP model chat functie. Type 'stop' om chat te beëindigen.\n",
      "Gebruiker: Hello\n",
      "Bot antwoord: Hi human, please tell me your GeniSys user\n",
      "Gebruiker: This user is Boris\n",
      "Bot antwoord: Great! Hi <HUMAN>! How can I help?\n",
      "Gebruiker: How are you?\n",
      "Bot antwoord: Hello, how are you? I am great thanks! Please tell me your GeniSys user\n",
      "Gebruiker: Its Boris\n",
      "Bot antwoord: Cool! Hello <HUMAN>, what can I do for you?\n",
      "Gebruiker: Bye\n",
      "Bot antwoord: See you later\n",
      "Tot ziens!\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"NLP model chat functie. Type 'stop' om chat te beëindigen.\")\n",
    "    \n",
    "    while True:\n",
    "        sentence = input(\"Jouw zin: \")\n",
    "        \n",
    "        if sentence.lower() == \"stop\":\n",
    "            print(\"Tot ziens!\")\n",
    "            break\n",
    "        \n",
    "        tokenized_sentence = tokenize(sentence)\n",
    "        bag = bag_of_words(tokenized_sentence, all_words)\n",
    "        \n",
    "        input_data = torch.tensor(bag, dtype=torch.float32)\n",
    "        output = model(input_data)\n",
    "        \n",
    "        _, predicted = torch.max(output, dim=0)\n",
    "        predicted_tag = tags[predicted.item()]\n",
    "        \n",
    "        for intent in data[\"intents\"]:\n",
    "            if intent[\"intent\"] == predicted_tag:\n",
    "                response = random.choice(intent[\"responses\"])\n",
    "                print(f\"Gebruiker: {sentence}\")\n",
    "                print(f\"Bot antwoord: {response}\")\n",
    "\n",
    "chat() #Begint de chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
