{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries importeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "      <th>focus_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is (are) Glaucoma ?</td>\n",
       "      <td>Glaucoma is a group of diseases that can damag...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Glaucoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What causes Glaucoma ?</td>\n",
       "      <td>Nearly 2.7 million people have glaucoma, a lea...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Glaucoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the symptoms of Glaucoma ?</td>\n",
       "      <td>Symptoms of Glaucoma  Glaucoma can develop in ...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Glaucoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the treatments for Glaucoma ?</td>\n",
       "      <td>Although open-angle glaucoma cannot be cured, ...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Glaucoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is (are) Glaucoma ?</td>\n",
       "      <td>Glaucoma is a group of diseases that can damag...</td>\n",
       "      <td>NIHSeniorHealth</td>\n",
       "      <td>Glaucoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question  \\\n",
       "0                What is (are) Glaucoma ?   \n",
       "1                  What causes Glaucoma ?   \n",
       "2     What are the symptoms of Glaucoma ?   \n",
       "3  What are the treatments for Glaucoma ?   \n",
       "4                What is (are) Glaucoma ?   \n",
       "\n",
       "                                              answer           source  \\\n",
       "0  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n",
       "1  Nearly 2.7 million people have glaucoma, a lea...  NIHSeniorHealth   \n",
       "2  Symptoms of Glaucoma  Glaucoma can develop in ...  NIHSeniorHealth   \n",
       "3  Although open-angle glaucoma cannot be cured, ...  NIHSeniorHealth   \n",
       "4  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n",
       "\n",
       "  focus_area  \n",
       "0   Glaucoma  \n",
       "1   Glaucoma  \n",
       "2   Glaucoma  \n",
       "3   Glaucoma  \n",
       "4   Glaucoma  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/medquad.csv\")\n",
    "df['question'] = df['question'].astype(str)\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "df['focus_area'] = df['focus_area'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train- en test data maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13129\n",
      "3283\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2)\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laad het model en de tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model runt op cuda\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "component = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                         else \"cpu\")\n",
    "model = model.to(component)\n",
    "print(f\"Model runt op {component}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data tokenizen en omzetten naar hugging face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50cccf67a2845e19437ff92cf80022f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c20a10d54b43f392c18de604501a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3283 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_data(data):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_questions = tokenizer(data['question'], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "    tokenized_answers = tokenizer(data['answer'], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    tokenized_focus_areas = tokenizer(data['focus_area'], padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": tokenized_questions[\"input_ids\"].squeeze(),\n",
    "        \"labels\": tokenized_answers[\"input_ids\"].squeeze(),\n",
    "        \"focus_area_ids\": tokenized_focus_areas[\"input_ids\"].squeeze(),\n",
    "        \"attention_mask\": tokenized_questions[\"attention_mask\"].squeeze()\n",
    "    }\n",
    "    \n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "train_dataset = train_dataset.map(tokenize_data, batched=True, remove_columns=[\"question\", \"answer\", \"focus_area\", \"source\"])\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "test_dataset = test_dataset.map(tokenize_data, batched=True, remove_columns=[\"question\", \"answer\", \"focus_area\", \"source\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop starten (doe dit alsjeblieft een non-cuda pc niet aan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is vrij zwaar, ongeveer 30 minuten met een RTX 3080. Je kan ook de training eventueel overslaan en een opgeslagen model laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16415' max='16415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16415/16415 31:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.391000</td>\n",
       "      <td>3.207007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.192400</td>\n",
       "      <td>3.061324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.998100</td>\n",
       "      <td>2.979790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.870200</td>\n",
       "      <td>2.977105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.420300</td>\n",
       "      <td>3.025535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"Getrainde_modellen/HouseMD_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir=\"Getrainde_modellen/HouseMD_model/logs\",\n",
    "    logging_steps=50,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    "    )\n",
    "\n",
    "trainer.train()\n",
    "torch.save(model.state_dict(), \"Getrainde_modellen/HouseMD_model/HouseMD_Model_gewichten.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"Getrainde_modellen/HouseMD_model/HouseMD_Model_gewichten.pth\",\n",
    "                                 map_location=torch.device(component)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oprecht de meest inefficiënte code die ik heb geschreven in een tijdje, maar het werkt weetje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evalueren: 100%|██████████| 52/52 [04:48<00:00,  5.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuratie op focus area: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct_voorspeld = 0 \n",
    "totaal_voorspeld = 0\n",
    "aantal_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc=\"Evalueren\", unit=\"batch\"):\n",
    "        aantal_batches += 64\n",
    "        \n",
    "        input_ids = data[\"input_ids\"].to(component)\n",
    "        focus_area_labels = data[\"focus_area_ids\"].to(component)\n",
    "\n",
    "        output = model(input_ids)\n",
    "        logits = output.logits\n",
    "        \n",
    "        focus_token_pred = logits[:, 0, :]\n",
    "        predicted_tokens_ids = torch.argmax(focus_token_pred, dim=-1)\n",
    "\n",
    "        focus_token_true = focus_area_labels[:, 0]\n",
    "\n",
    "        correct_voorspeld += (predicted_tokens_ids  == focus_token_true).sum().item()\n",
    "        totaal_voorspeld += focus_area_labels.size(0)\n",
    "\n",
    "accuratie = correct_voorspeld / totaal_voorspeld * 100\n",
    "print(f\"Model accuratie op focus area: {accuratie:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
