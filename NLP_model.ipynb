{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries importeren en random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2797ddb4810>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data inladen en naar dataframe omzetten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>[Hi, Hi there, Hola, Hello, Hello there, Hya, ...</td>\n",
       "      <td>[Hi human, please tell me your GeniSys user, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>[My user is Adam, This is Adam, I am Adam, It ...</td>\n",
       "      <td>[Great! Hi &lt;HUMAN&gt;! How can I help?, Good! Hi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CourtesyGreeting</td>\n",
       "      <td>[How are you?, Hi how are you?, Hello how are ...</td>\n",
       "      <td>[Hello, I am great, how are you? Please tell m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CourtesyGreetingResponse</td>\n",
       "      <td>[Good thanks! My user is Adam, Good thanks! Th...</td>\n",
       "      <td>[Great! Hi &lt;HUMAN&gt;! How can I help?, Good! Hi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CurrentHumanQuery</td>\n",
       "      <td>[What is my name?, What do you call me?, Who d...</td>\n",
       "      <td>[You are &lt;HUMAN&gt;! How can I help?, Your name i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     intent  \\\n",
       "0                  Greeting   \n",
       "1          GreetingResponse   \n",
       "2          CourtesyGreeting   \n",
       "3  CourtesyGreetingResponse   \n",
       "4         CurrentHumanQuery   \n",
       "\n",
       "                                                text  \\\n",
       "0  [Hi, Hi there, Hola, Hello, Hello there, Hya, ...   \n",
       "1  [My user is Adam, This is Adam, I am Adam, It ...   \n",
       "2  [How are you?, Hi how are you?, Hello how are ...   \n",
       "3  [Good thanks! My user is Adam, Good thanks! Th...   \n",
       "4  [What is my name?, What do you call me?, Who d...   \n",
       "\n",
       "                                           responses  \n",
       "0  [Hi human, please tell me your GeniSys user, H...  \n",
       "1  [Great! Hi <HUMAN>! How can I help?, Good! Hi ...  \n",
       "2  [Hello, I am great, how are you? Please tell m...  \n",
       "3  [Great! Hi <HUMAN>! How can I help?, Good! Hi ...  \n",
       "4  [You are <HUMAN>! How can I help?, Your name i...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open('Data/Intent.json'))\n",
    "df = pd.DataFrame(data['intents'])\n",
    "df = df[['intent', 'text', 'responses']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functies maken voor tokenizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\boris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence.lower())\n",
    "\n",
    "def stem (word):\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "    sentence_words = [stem(w) for w in tokenized_sentence]\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Woordenlijst maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    tag = intent[\"intent\"]\n",
    "    tags.append(tag)\n",
    "    \n",
    "    for pattern in intent[\"text\"]:\n",
    "        w = tokenize(pattern)\n",
    "        all_words.extend(w)\n",
    "        xy.append((w, tag))\n",
    "        \n",
    "all_words = sorted(set(stem(w) for w in all_words if w not in [\"?\", \".\", \"!\"]))\n",
    "tags = sorted(set(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traindata samenstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for pattern_sentence, tag in xy:\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    Y_train.append(tags.index(tag))\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = Y_train\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.x_data[index], dtype=torch.float32), torch.tensor(self.y_data[index], dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=8, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intent Classifier netwerk bouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(len(X_train[0]), 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, len(tags))\n",
    ")\n",
    "print(len(X_train[0]))\n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss & optimalisator declareren en check voor cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "criterium = nn.CrossEntropyLoss()\n",
    "optimalisator = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "component = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                         else \"cpu\")\n",
    "model = model.to(component)\n",
    "print(component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100 / 500], Loss: 0.0081\n",
      "Epoch [200 / 500], Loss: 0.0042\n",
      "Epoch [300 / 500], Loss: 0.0013\n",
      "Epoch [400 / 500], Loss: 0.0002\n",
      "Epoch [500 / 500], Loss: 0.0000\n",
      "Training voltooid! Gewichten opslaan...\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for words, labels in train_loader:\n",
    "                \n",
    "        words = words.to(component)\n",
    "        labels = labels.to(component)\n",
    "        \n",
    "        outputs = model(words)\n",
    "        loss = criterium(outputs, labels)\n",
    "        \n",
    "        optimalisator.zero_grad()\n",
    "        loss.backward()\n",
    "        optimalisator.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch + 1} / {num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "print(\"Training voltooid! Gewichten opslaan...\")\n",
    "torch.save(model.state_dict(), \"Getrainde_modellen/NLP_Model_gewichten.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"Getrainde_modellen/NLP_Model_gewichten.pth\", \n",
    "                                 map_location=torch.device(component)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratie na training: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct_voorspeld = 0\n",
    "    totaal_voorspeld = 0\n",
    "    \n",
    "    for words, labels in train_loader:\n",
    "        words, labels = words.to(component), labels.to(component)\n",
    "        test_output = model(words)\n",
    "        _, predicted = torch.max(test_output, 1)\n",
    "        correct_voorspeld += (predicted == labels).sum().item()\n",
    "        totaal_voorspeld += labels.size(0)\n",
    "\n",
    "accuratie = correct_voorspeld / totaal_voorspeld * 100\n",
    "\n",
    "print(f\"Accuratie na training: {accuratie:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat implementatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP model chat functie. Type 'stop' om chat te beëindigen.\n",
      "Voorspelde intent: Greeting\n",
      "Gebruiker antwoord: Hello\n",
      "Intentie: Greeting, Antwoord: Hi human, please tell me your GeniSys user\n",
      "Voorspelde intent: WhoAmI\n",
      "Gebruiker antwoord: Can you see me?\n",
      "Intentie: WhoAmI, Antwoord: Let me see\n",
      "Voorspelde intent: Greeting\n",
      "Gebruiker antwoord: Okay\n",
      "Intentie: Greeting, Antwoord: Hello human, please tell me your GeniSys user\n",
      "Voorspelde intent: NameQuery\n",
      "Gebruiker antwoord: Are you AI?\n",
      "Intentie: NameQuery, Antwoord: You may call me Geni\n",
      "Voorspelde intent: SelfAware\n",
      "Gebruiker antwoord: Are you self aware?\n",
      "Intentie: SelfAware, Antwoord: That is an difficult question, can you prove that you are?\n",
      "Voorspelde intent: Thanks\n",
      "Gebruiker antwoord: Thanks!\n",
      "Intentie: Thanks, Antwoord: My pleasure\n",
      "Voorspelde intent: GoodBye\n",
      "Gebruiker antwoord: Bye bye\n",
      "Intentie: GoodBye, Antwoord: See you later\n",
      "Tot ziens!\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"NLP model chat functie. Type 'stop' om chat te beëindigen.\")\n",
    "    \n",
    "    while True:\n",
    "        sentence = input(\"Jouw zin: \")\n",
    "        \n",
    "        if sentence.lower() == \"stop\":\n",
    "            print(\"Tot ziens!\")\n",
    "            break\n",
    "        \n",
    "        tokenized_sentence = tokenize(sentence)\n",
    "        bag = bag_of_words(tokenized_sentence, all_words)\n",
    "        \n",
    "        input_data = torch.tensor(bag, dtype=torch.float32)\n",
    "        output = model(input_data)\n",
    "        \n",
    "        _, predicted = torch.max(output, dim=0)\n",
    "        predicted_tag = tags[predicted.item()]\n",
    "        print(f\"Voorspelde intent: {predicted_tag}\")\n",
    "        \n",
    "        gevonden_intentie = next((intent for intent in data[\"intents\"]\n",
    "                                  if intent[\"intent\"] == predicted_tag), None)\n",
    "        if gevonden_intentie:\n",
    "            response = random.choice(gevonden_intentie[\"responses\"])\n",
    "        else:\n",
    "            response = \"Wollah wat zeg jij.\"\n",
    "        print(f\"Gebruiker antwoord: {sentence}\", flush=True)\n",
    "        print(f\"Intentie: {predicted_tag}, Antwoord: {response}\", flush=True)\n",
    "        \n",
    "chat() #Begint de chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
