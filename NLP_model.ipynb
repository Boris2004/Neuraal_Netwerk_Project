{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries importeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data inladen en naar dataframe omzetten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>[Hi, Hi there, Hola, Hello, Hello there, Hya, ...</td>\n",
       "      <td>[Hi human, please tell me your GeniSys user, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>[My user is Adam, This is Adam, I am Adam, It ...</td>\n",
       "      <td>[Great! Hi &lt;HUMAN&gt;! How can I help?, Good! Hi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CourtesyGreeting</td>\n",
       "      <td>[How are you?, Hi how are you?, Hello how are ...</td>\n",
       "      <td>[Hello, I am great, how are you? Please tell m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CourtesyGreetingResponse</td>\n",
       "      <td>[Good thanks! My user is Adam, Good thanks! Th...</td>\n",
       "      <td>[Great! Hi &lt;HUMAN&gt;! How can I help?, Good! Hi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CurrentHumanQuery</td>\n",
       "      <td>[What is my name?, What do you call me?, Who d...</td>\n",
       "      <td>[You are &lt;HUMAN&gt;! How can I help?, Your name i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     intent  \\\n",
       "0                  Greeting   \n",
       "1          GreetingResponse   \n",
       "2          CourtesyGreeting   \n",
       "3  CourtesyGreetingResponse   \n",
       "4         CurrentHumanQuery   \n",
       "\n",
       "                                                text  \\\n",
       "0  [Hi, Hi there, Hola, Hello, Hello there, Hya, ...   \n",
       "1  [My user is Adam, This is Adam, I am Adam, It ...   \n",
       "2  [How are you?, Hi how are you?, Hello how are ...   \n",
       "3  [Good thanks! My user is Adam, Good thanks! Th...   \n",
       "4  [What is my name?, What do you call me?, Who d...   \n",
       "\n",
       "                                           responses  \n",
       "0  [Hi human, please tell me your GeniSys user, H...  \n",
       "1  [Great! Hi <HUMAN>! How can I help?, Good! Hi ...  \n",
       "2  [Hello, I am great, how are you? Please tell m...  \n",
       "3  [Great! Hi <HUMAN>! How can I help?, Good! Hi ...  \n",
       "4  [You are <HUMAN>! How can I help?, Your name i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.load(open('Data/Intent.json'))\n",
    "df = pd.DataFrame(data['intents'])\n",
    "df = df[['intent', 'text', 'responses']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functies maken voor tokenizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\boris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence.lower())\n",
    "\n",
    "def stem (word):\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "    sentence_words = [stem(w) for w in tokenized_sentence]\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Woordenlijst en trainingdata maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "\n",
    "for _, intent in df.iterrows():\n",
    "    tag = intent[\"intent\"]\n",
    "    tags.append(tag)\n",
    "    \n",
    "    for pattern in intent[\"text\"]:\n",
    "        w = tokenize(pattern)\n",
    "        all_words.extend(w)\n",
    "        xy.append((w, tag))\n",
    "        \n",
    "all_words = sorted(set(stem(w) for w in all_words if w not in [\"?\", \".\", \"!\"]))\n",
    "tags = sorted(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for pattern_sentence, tag in xy:\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    Y_train.append(tags.index(tag))\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
